{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python390jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d",
   "display_name": "Python 3.9.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Recherche du meilleur modèle\n",
    "Charge successivement les poids des modèles fine tuned et teste ces valeurs sur le jeu de messages annotés\n",
    "Le modèle avec le meilleur score f1 est gardé."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pyplot\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from transformers import TFCamembertForSequenceClassification\n",
    "import transformers.models.camembert.tokenization_camembert as tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 905839099126918692,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 2249614951\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 15951191490776824107\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\"]"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"jplu/tf-camembert-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_reviews(tokenizer, reviews, max_length):\n",
    "    token_ids = np.zeros(shape=(len(reviews), max_length),\n",
    "                         dtype=np.int32)\n",
    "    for i, review in enumerate(reviews):\n",
    "        encoded = tokenizer.encode(review, max_length=max_length)\n",
    "        token_ids[i, 0:len(encoded)] = encoded\n",
    "    attention_mask = (token_ids != 0).astype(np.int32)\n",
    "    return {\"input_ids\": token_ids, \"attention_mask\": attention_mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(x, mdl):\n",
    "    scores = mdl.predict(x)\n",
    "    y_pred = np.argmax(scores['logits'], axis=1)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(y,y_pred,graph=True):\n",
    "    TP = np.count_nonzero(y*y_pred)\n",
    "    TN = np.count_nonzero((y-1)*(y_pred-1))\n",
    "    FN = np.count_nonzero((y-1)*y_pred)\n",
    "    FP = np.count_nonzero(y*(y_pred-1))\n",
    "    tot = TP+TN+FN+FP\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y, y_pred)\n",
    "    f1_score = metrics.f1_score(y, y_pred)\n",
    "    conf_mx = metrics.confusion_matrix(y, y_pred)\n",
    "\n",
    "    conf_matrix = [[TN,FN],[FP,TP]]\n",
    "    if((TP+FP) != 0 and (TP+FN) != 0):\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    else:\n",
    "        precision = accuracy\n",
    "        recall = -1\n",
    "        f1 = f1_score\n",
    "\n",
    "    print(f\"Precision: {round(100 * precision,2)}\")\n",
    "    print(f\"Rappel: {round(100 * recall,2)}\")\n",
    "    print(f\"F-score: {round(100 * f1,2)}\")\n",
    "    print(f\"%bon: {round(100*(TP+TN)/tot,2)} - %faux: {round(100*(FP+FN)/tot,2)}\")\n",
    "    print(f\"Matrice: {conf_matrix}\")\n",
    "    if(graph):\n",
    "        sns.heatmap(conf_matrix)\n",
    "    return [precision,recall,f1,conf_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tk.CamembertTokenizer.from_pretrained(model_name,do_lower_case=True)\n",
    "assert tokenizer != None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "data_messages = pd.read_csv(\"./messages/messages0.csv\")\n",
    "msg_labels = data_messages['sentiments'].values.tolist()\n",
    "msg = data_messages['messages'].values.tolist()\n",
    "\n",
    "encoded_msg = encode_reviews(tokenizer, msg, 200)\n",
    "y_msg = np.array(msg_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "All model checkpoint layers were used when initializing TFCamembertForSequenceClassification.\n",
      "\n",
      "Some layers of TFCamembertForSequenceClassification were not initialized from the model checkpoint at jplu/tf-camembert-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model1 = TFCamembertForSequenceClassification.from_pretrained(model_name)\n",
    "olds = [\"f169_count8000_epo5_batch4.h5\",\"f171_count5000_epo8_batch24.h5\",\"f172_count500_epo8_batch24.h5\",\"f177_count3680_epo3_batch12.h5\",\"f176_count3680_epo10_batch14.h5\",\"f179_count8000_epo7_batch4.h5\",\"f179_count1000_epo8_batch24.h5\",\"f180_count1000_epo5_batch8.h5\",\"f180_count10000_epo15_batch8.h5\",\"f180_count36800_epo10_batch16.h5\",\"f181_count720_epo20_batch4.h5\",\"f193_count8000_epo7_batch4_allo.h5\",\"f194_count8000_epo10_batch4_allo.h5\"]\n",
    "models_weights = [\n",
    "    \"f145_count2500_epo15_batch24.h5\", \n",
    "    \"f153_count1000_epo15_batch16.h5\",\n",
    "    \"f179_count1440_epo20_batch24.h5\",\n",
    "    \"f179_count8000_epo18_batch4.h5\",\n",
    "    \"f179_count8000_epo20_batch4.h5\",\n",
    "    \"f179_count12000_epo10_batch8.h5\",\n",
    "    \"f182_count720_epo20_batch24.h5\",\n",
    "    \"f184_count522_epo10_batch16.h5\",\n",
    "    \"f184_count720_epo20_batch16.h5\",\n",
    "    \"f191_count8000_epo3_batch4_allo.h5\"]\n",
    "models_score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "--- f145_count2500_epo15_batch24.h5\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Precision: 81.07\n",
      "Rappel: 75.69\n",
      "F-score: 78.29\n",
      "%bon: 72.66 - %faux: 27.34\n",
      "Matrice: [[65, 44], [32, 137]]\n",
      "+++\n",
      "\n",
      "--- f153_count1000_epo15_batch16.h5\n",
      "Precision: 86.39\n",
      "Rappel: 71.57\n",
      "F-score: 78.28\n",
      "%bon: 70.86 - %faux: 29.14\n",
      "Matrice: [[51, 58], [23, 146]]\n",
      "+++\n",
      "\n",
      "--- f179_count1440_epo20_batch24.h5\n",
      "Precision: 82.84\n",
      "Rappel: 72.92\n",
      "F-score: 77.56\n",
      "%bon: 70.86 - %faux: 29.14\n",
      "Matrice: [[57, 52], [29, 140]]\n",
      "+\n",
      "\n",
      "--- f179_count8000_epo18_batch4.h5\n",
      "Precision: 84.02\n",
      "Rappel: 74.74\n",
      "F-score: 79.11\n",
      "%bon: 73.02 - %faux: 26.98\n",
      "Matrice: [[61, 48], [27, 142]]\n",
      "*\n",
      "\n",
      "--- f179_count8000_epo20_batch4.h5\n",
      "Precision: 84.02\n",
      "Rappel: 75.13\n",
      "F-score: 79.33\n",
      "%bon: 73.38 - %faux: 26.62\n",
      "Matrice: [[62, 47], [27, 142]]\n",
      "*\n",
      "\n",
      "--- f179_count12000_epo10_batch8.h5\n",
      "Precision: 79.88\n",
      "Rappel: 75.42\n",
      "F-score: 77.59\n",
      "%bon: 71.94 - %faux: 28.06\n",
      "Matrice: [[65, 44], [34, 135]]\n",
      "+\n",
      "\n",
      "--- f182_count720_epo20_batch24.h5\n",
      "Precision: 82.84\n",
      "Rappel: 73.3\n",
      "F-score: 77.78\n",
      "%bon: 71.22 - %faux: 28.78\n",
      "Matrice: [[58, 51], [29, 140]]\n",
      "+\n",
      "\n",
      "--- f184_count522_epo10_batch16.h5\n",
      "Precision: 85.8\n",
      "Rappel: 73.23\n",
      "F-score: 79.02\n",
      "%bon: 72.3 - %faux: 27.7\n",
      "Matrice: [[56, 53], [24, 145]]\n",
      "*\n",
      "\n",
      "--- f184_count720_epo20_batch16.h5\n",
      "Precision: 83.43\n",
      "Rappel: 75.0\n",
      "F-score: 78.99\n",
      "%bon: 73.02 - %faux: 26.98\n",
      "Matrice: [[62, 47], [28, 141]]\n",
      "+++++\n",
      "\n",
      "--- f191_count8000_epo3_batch4_allo.h5\n",
      "Precision: 84.62\n",
      "Rappel: 72.59\n",
      "F-score: 78.14\n",
      "%bon: 71.22 - %faux: 28.78\n",
      "Matrice: [[55, 54], [26, 143]]\n",
      "+++\n"
     ]
    }
   ],
   "source": [
    "best = [0,0,0,0]\n",
    "best_name = \"\"\n",
    "for w in models_weights:\n",
    "    model1.load_weights(f\"./models_weights/{w}\")\n",
    "    print(f'\\n--- {w}')\n",
    "    y_pred = prediction(encoded_msg, model1)\n",
    "    score = evaluation(y_msg,y_pred,graph=False)\n",
    "    if(score[2]<0.77): print(\"-\")\n",
    "    elif(score[2]<0.775): print(\"\")\n",
    "    elif(score[2]<0.78): print(\"+\")\n",
    "    elif(score[2]<0.785): print(\"+++\")\n",
    "    elif(score[2]<0.79): print(\"+++++\")\n",
    "    elif(score[2]<0.80): print(\"*\")\n",
    "    else: print(\"***\")\n",
    "\n",
    "    if(score[2] > best[2]):\n",
    "        best = score\n",
    "        best_name = w\n",
    "    models_score.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "f179_count8000_epo20_batch4.h5\n[0.8402366863905325, 0.7513227513227513, 0.7932960893854748, [[62, 47], [27, 142]]]\n"
     ]
    }
   ],
   "source": [
    "print(best_name)\n",
    "print(best)\n",
    "# f179_count8000_epo18_batch4.h5\n",
    "# [0.8373493975903614, 0.7473118279569892, 0.7897727272727273, [[61, 47], [27, 139]]]"
   ]
  }
 ]
}