{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python390jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d",
   "display_name": "Python 3.9.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Extracteur d'entitées dans les messages\n",
    "### Objectif\n",
    "On souhaite extraire automatiquement, grace à spaCy (un outil de traitement naturel du langage en python), les entitées (personnes, lieux, concepts, objets) qui apparaissent dans les messages récupérés et sur lequels on va appliquer l'analyse de sentiment.\n",
    "### Remarque\n",
    "Les messages d'une conversation telle que celle que je traite sont écrit avec des contractions, des néologismes, des fautes et une structure de langage parlé. spaCy n'est pas entrainé sur ce genre de texte. \n",
    "Un trie à la main est nécessaire par la suite. Pour cette tache j'ai utilisé le script: entities_selector.py"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy.lang.fr.examples import sentences "
   ]
  },
  {
   "source": [
    "### Récupération du fichier json contenant les messages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('./messages/BDE_8223.json', encoding=\"utf8\") as f:\n",
    "  data = json.load(f)"
   ]
  },
  {
   "source": [
    "### Chargement de l'outil spaCy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"fr_core_news_sm\")"
   ]
  },
  {
   "source": [
    "### Extraction des entitées"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = []\n",
    "for e in data:\n",
    "    msg = e[\"what\"]\n",
    "    doc = nlp(msg)\n",
    "    for ent in doc.ents:\n",
    "        ent_txt = ent.text.lower()\n",
    "        # premier trie des entitées extraites\n",
    "        if len(ent_txt) > 1:\n",
    "            if not(ent_txt[1] == '’' and len(ent_txt) == 2) and ent_txt not in entities:\n",
    "                entities.append(ent_txt)"
   ]
  },
  {
   "source": [
    "### Affichage et sauvegarde des entitées"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1681\n"
     ]
    }
   ],
   "source": [
    "print(len(entities))\n",
    "pd.DataFrame(entities).to_csv('./entities/entities.csv')"
   ]
  }
 ]
}