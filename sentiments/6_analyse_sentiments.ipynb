{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python380jvsc74a57bd0ce3b06770faf0e6893568bbd941b41c6a595c4ed68e9c90b28e9aa1486d3cef9",
   "display_name": "Python 3.8.0 64-bit ('tf_2.4': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Analyse des sentiements liées aux entitées\n",
    "On souhaite ici compter le nombre de messages décrit comme \"positif\" et \"négatif\" comptenant une entitée\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install tensorflow\n",
    "!pip install transformers\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "source": [
    "import tensorflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from transformers import TFCamembertForSequenceClassification\n",
    "import transformers.models.camembert.tokenization_camembert as tk"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": []
  },
  {
   "source": [
    "### Chargement des messages et des entitées"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./messages/BDE_8223.json', encoding=\"utf8\") as f:\n",
    "  messages = json.load(f)\n",
    "\n",
    "with open('./entities/entities_final.json', encoding=\"utf8\") as f:\n",
    "  entities = json.load(f)"
   ]
  },
  {
   "source": [
    "### Récuparation de l'encodeur pour notre modèle"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tk.CamembertTokenizer.from_pretrained(\"jplu/tf-camembert-base\",do_lower_case=True)\n",
    "assert tokenizer != None\n",
    "\n",
    "def encode_msg(messages, tokenizer = tokenizer, max_length=80):\n",
    "    token_ids = np.zeros(shape=(len(messages), max_length),\n",
    "                         dtype=np.int32)\n",
    "    for i, msg in enumerate(messages):\n",
    "        encoded = tokenizer.encode(msg, max_length=max_length)\n",
    "        token_ids[i, 0:len(encoded)] = encoded\n",
    "    attention_mask = (token_ids != 0).astype(np.int32)\n",
    "    return {\"input_ids\": token_ids, \"attention_mask\": attention_mask}"
   ]
  },
  {
   "source": [
    "### Chargement de notre modèle fine-tuned"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "All model checkpoint layers were used when initializing TFCamembertForSequenceClassification.\n",
      "\n",
      "Some layers of TFCamembertForSequenceClassification were not initialized from the model checkpoint at jplu/tf-camembert-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFCamembertForSequenceClassification.from_pretrained(\"jplu/tf-camembert-base\")\n",
    "model.load_weights(\"./models_weights/f179_count8000_epo20_batch4.h5\")"
   ]
  },
  {
   "source": [
    "### Pré-traitement de notre jeu de donnée\n",
    "On écarte les messages comptenant des liens, des gif et des enregistrement vocaux. On ne garde pas non plus les messages de moins de 2 caractères ainsi que les messages à plus de 120 caractères car le modèle a été entrainé sur des messages courts.\n",
    "\n",
    "On format aussi les données en ne gardant que le contenu et l'auteur du messages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6972 messages gardés\n"
     ]
    }
   ],
   "source": [
    "# entrée (messages) { who:.., what:.., when:.., feedback:.., whatType:..},{..},{..},..\n",
    "# sortie (messages_keep) [[what, who],[],..]\n",
    "\n",
    "messages_keep = [[m['what'],m['who']] for m in messages if m['whatType'] == \"Texte\"]\n",
    "\n",
    "df = pd.DataFrame(messages_keep,columns=['messages','auteur'])\n",
    "print(f\"{len(df)} messages gardés\")"
   ]
  },
  {
   "source": [
    "### Prédiction des sentiements avec le modèle fine tuned"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x0000026D942F01C0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x0000026D942F01C0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                            messages   auteur  sentiment\n",
       "0  Mais elle a même pas présenté ce que c'était l...  Fanny-T          0\n",
       "1                         Bah tu fais ce que tu veux  Olivier          1\n",
       "2                Elle a dit qu’on fait ce qu’on veut       Al          1\n",
       "3                                                Meh  Fanny-T          1\n",
       "4  Mais la vous avez tous des projets ou vous dem...       Al          0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>messages</th>\n      <th>auteur</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Mais elle a même pas présenté ce que c'était l...</td>\n      <td>Fanny-T</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Bah tu fais ce que tu veux</td>\n      <td>Olivier</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Elle a dit qu’on fait ce qu’on veut</td>\n      <td>Al</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Meh</td>\n      <td>Fanny-T</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Mais la vous avez tous des projets ou vous dem...</td>\n      <td>Al</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# sortie [[what,who,sentiment],..]\n",
    "\n",
    "messages_array = df.iloc[:,0].values\n",
    "encoded_messages = encode_msg(messages_array)\n",
    "\n",
    "scores = model.predict(encoded_messages)\n",
    "sent_pred = np.argmax(scores['logits'], axis=1)\n",
    "df['sentiment'] = sent_pred\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "63.4% messages positifs (4422)\n36.6% messages négatifs (2550)\n"
     ]
    }
   ],
   "source": [
    "mneg = df.iloc[:,2].value_counts(0)[0]\n",
    "mpos = df.iloc[:,2].value_counts(0)[1]\n",
    "tot = mpos+mneg\n",
    "print(f\"{round(100 * mpos/tot,1)}% messages positifs ({mpos})\")\n",
    "print(f\"{round(100 * mneg/tot,1)}% messages négatifs ({mneg})\")"
   ]
  },
  {
   "source": [
    "### Coloration des entitées\n",
    "Association pour chaque entitées(groupe de mot) du nombre de messagse positif et négatif comptenant un des mots liées à l'entitée"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sortie [{entities: [n_positif,n_negatif,diff] }]\n",
    "\n",
    "def containOneOf(message,elements):\n",
    "    for e in elements:\n",
    "        if e in message.lower():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "entities_with_sentiment = {}\n",
    "\n",
    "n_sans_entity = 0\n",
    "for row in df.to_numpy():\n",
    "    sans_entity = True\n",
    "    for ent in entities:\n",
    "        if containOneOf(row[0],entities[ent]):\n",
    "            arr = np.array([0,0,0,0])\n",
    "            arr[row[2]] = 1\n",
    "            if ent not in entities_with_sentiment:\n",
    "                entities_with_sentiment[ent] = arr.tolist()\n",
    "            else:\n",
    "                entities_with_sentiment[ent] = (np.array(arr)+np.array(entities_with_sentiment[ent])).tolist()\n",
    "            sans_entity = False\n",
    "    if sans_entity:\n",
    "        n_sans_entity += 1\n",
    "\n",
    "# ajout de la différence sentiement pos - neg\n",
    "for ent in entities_with_sentiment:\n",
    "    entities_with_sentiment[ent][2] = entities_with_sentiment[ent][1] - entities_with_sentiment[ent][0] \n",
    "    entities_with_sentiment[ent][3] = round(100*entities_with_sentiment[ent][1]/(entities_with_sentiment[ent][1] + entities_with_sentiment[ent][0]))\n",
    "\n",
    "# sauvegarde de l'analyse\n",
    "with open('analyse.json', 'w', encoding=\"utf8\") as fout:\n",
    "    json.dump(entities_with_sentiment, fout, ensure_ascii=False)"
   ]
  },
  {
   "source": [
    "### Convertion du dict en DataFrame pour visualiser le résultat"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       entity  negatif  positif  diff  pourcent\n",
       "11      julie       39      138    99        78\n",
       "39     soirée       19       56    37        75\n",
       "12   juliette       13       43    30        77\n",
       "36        wec       17       45    28        73\n",
       "3      albane        4       29    25        88\n",
       "..        ...      ...      ...   ...       ...\n",
       "104      chat        3        1    -2        25\n",
       "53     orange        5        3    -2        38\n",
       "17    kermess        4        1    -3        20\n",
       "88       gala        7        4    -3        36\n",
       "92         pc        5        1    -4        17\n",
       "\n",
       "[123 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>entity</th>\n      <th>negatif</th>\n      <th>positif</th>\n      <th>diff</th>\n      <th>pourcent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <td>julie</td>\n      <td>39</td>\n      <td>138</td>\n      <td>99</td>\n      <td>78</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>soirée</td>\n      <td>19</td>\n      <td>56</td>\n      <td>37</td>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>juliette</td>\n      <td>13</td>\n      <td>43</td>\n      <td>30</td>\n      <td>77</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>wec</td>\n      <td>17</td>\n      <td>45</td>\n      <td>28</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>albane</td>\n      <td>4</td>\n      <td>29</td>\n      <td>25</td>\n      <td>88</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>104</th>\n      <td>chat</td>\n      <td>3</td>\n      <td>1</td>\n      <td>-2</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>orange</td>\n      <td>5</td>\n      <td>3</td>\n      <td>-2</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>kermess</td>\n      <td>4</td>\n      <td>1</td>\n      <td>-3</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>gala</td>\n      <td>7</td>\n      <td>4</td>\n      <td>-3</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>pc</td>\n      <td>5</td>\n      <td>1</td>\n      <td>-4</td>\n      <td>17</td>\n    </tr>\n  </tbody>\n</table>\n<p>123 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# conversion dictionnaire en list\n",
    "entities_with_sentiment_list = []\n",
    "for key in entities_with_sentiment:\n",
    "    temp = [key,entities_with_sentiment[key][0],entities_with_sentiment[key][1],entities_with_sentiment[key][2],entities_with_sentiment[key][3]]\n",
    "    entities_with_sentiment_list.append(temp)\n",
    "\n",
    "# conversion list en dataframe + trie\n",
    "df_senti = pd.DataFrame(entities_with_sentiment_list,columns=[\"entity\",\"negatif\",\"positif\",\"diff\",\"pourcent\"])\n",
    "\n",
    "df_senti = df_senti.sort_values(by=[\"diff\"],ascending=False)\n",
    "index = df_senti[df_senti[\"positif\"]+df_senti[\"negatif\"] <= 2].index\n",
    "df_senti = df_senti.drop(index)\n",
    "df_senti"
   ]
  },
  {
   "source": [
    "### Affichage des résultats"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1986   messags contenant une entitée (~28%)\n123    entitées apparaissant au moins 3 fois dans le corpus\n1841   associations (messages positifs, entitée)\n894    associations (messages négatifs, entitée)\n"
     ]
    }
   ],
   "source": [
    "msg_avec_entitees = len(messages_keep)-n_sans_entity\n",
    "print(f\"{msg_avec_entitees}   messags contenant une entitée (~{round(100*msg_avec_entitees/len(messages_keep))}%)\")\n",
    "print(f\"{len(df_senti)}    entitées apparaissant au moins 3 fois dans le corpus\")\n",
    "arr = np.array(entities_with_sentiment_list)\n",
    "neg = np.sum([int(n) for n in arr[:,1]])\n",
    "pos = np.sum([int(p) for p in arr[:,2]])\n",
    "print(f\"{pos}   associations (messages positifs, entitée)\")\n",
    "print(f\"{neg}    associations (messages négatifs, entitée)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(df,column):\n",
    "    if column == 3:\n",
    "        print(f\"{' '*17}Entités  +   -  diff\")\n",
    "    else:\n",
    "        print(f\"{' '*17}Entités  +   -   %\")\n",
    "    print(\"-\"*120)\n",
    "    n = 1\n",
    "    if(column==3):\n",
    "        df = df.sort_values(by=[\"diff\"],ascending=False)\n",
    "    else:\n",
    "        df = df.sort_values(by=[\"pourcent\"],ascending=False)\n",
    "    array_senti = df.to_numpy()\n",
    "    maxdiff = array_senti[0][column]\n",
    "    for row in array_senti:\n",
    "        spaces1 = 24-len(row[0])\n",
    "        nb_char = int(row[column]*70/maxdiff)\n",
    "        if(column == 4):\n",
    "            nb_char-=35\n",
    "        nb_moins = nb_plus = 0\n",
    "        if nb_char < 0:\n",
    "            nb_moins = -nb_char\n",
    "        else:\n",
    "            nb_plus = nb_char\n",
    "        spaces2 = 10-nb_moins\n",
    "        if column == 4:\n",
    "            spaces2 += 18\n",
    "        counts = [f\"{' '*(3-len(str(row[i])))}{row[i]}\" for i in [1,2,column]]\n",
    "        print(f\"{n}{' '*(spaces1-len(str(n)))}{row[0]} {counts[0]} {counts[1]} {counts[2]} {' '*spaces2}{'-'*nb_moins}|{'+'*nb_plus}\")\n",
    "        n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 Entités  +   -  diff\n------------------------------------------------------------------------------------------------------------------------\n1                  julie  39 138  99           |++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n2                 soirée  19  56  37           |++++++++++++++++++++++++++\n3               juliette  13  43  30           |+++++++++++++++++++++\n4                    wec  17  45  28           |+++++++++++++++++++\n5                 albane   4  29  25           |+++++++++++++++++\n6                 julien  22  47  25           |+++++++++++++++++\n7                  simon   8  31  23           |++++++++++++++++\n8                   paul   8  29  21           |++++++++++++++\n9                  élise   7  28  21           |++++++++++++++\n10               antoine  15  36  21           |++++++++++++++\n11                google   8  28  20           |++++++++++++++\n12                projet   6  26  20           |++++++++++++++\n13               matthéo  12  32  20           |++++++++++++++\n14                  zoom  25  44  19           |+++++++++++++\n15                    cm  41  60  19           |+++++++++++++\n16                 bière  18  37  19           |+++++++++++++\n17                  pull  24  42  18           |++++++++++++\n18              election   4  22  18           |++++++++++++\n19                margot  14  31  17           |++++++++++++\n20                romain  11  28  17           |++++++++++++\n21              campagne   4  20  16           |+++++++++++\n22                    3a   6  22  16           |+++++++++++\n23                 fanny  10  25  15           |++++++++++\n24                    ru   4  19  15           |++++++++++\n25                  tess  17  30  13           |+++++++++\n26                lydia    2  14  12           |++++++++\n27                  theo   7  19  12           |++++++++\n28                   bde  28  40  12           |++++++++\n29                 respo   9  20  11           |+++++++\n30                  ensc  50  61  11           |+++++++\n31                   wei  10  20  10           |+++++++\n32                  info   5  15  10           |+++++++\n33                   pii   2  12  10           |+++++++\n34                   léa   2  12  10           |+++++++\n35                    ia   1  11  10           |+++++++\n36                   bds  12  21   9           |++++++\n37              bordeaux  11  20   9           |++++++\n38                 vodka   2  11   9           |++++++\n39                  vert  14  22   8           |+++++\n40             octoflix    8  16   8           |+++++\n41               discord   2  10   8           |+++++\n42                nico l  18  26   8           |+++++\n43                marine   5  13   8           |+++++\n44              corentin   9  16   7           |++++\n45          compte rendu   8  15   7           |++++\n46               sabaidi  11  18   7           |++++\n47               shotgun   4  11   7           |++++\n48                tiktok   1   8   7           |++++\n49                ricard   1   7   6           |++++\n50                  hugo   1   7   6           |++++\n51                   d3a   0   6   6           |++++\n52                  rhum   1   7   6           |++++\n53               turn up   1   7   6           |++++\n54                   wes   0   6   6           |++++\n55                    tp   7  12   5           |+++\n56               poulpas   3   8   5           |+++\n57               netflix   0   5   5           |+++\n58                 apéro   4   8   4           |++\n59             instagram   3   7   4           |++\n60               calabar   2   6   4           |++\n61                wei&go   2   5   3           |++\n62                  gars  34  37   3           |++\n63                   bci   1   4   3           |++\n64                  meuf  12  15   3           |++\n65                 maths   8  11   3           |++\n66              vacances   8  11   3           |++\n67                  evan   7  10   3           |++\n68                  théa   4   7   3           |++\n69                   inp   2   4   2           |+\n70                 tom d  19  21   2           |+\n71                    1a  17  19   2           |+\n72                 foyer  16  18   2           |+\n73                   bda   9  11   2           |+\n74               mélissa   3   5   2           |+\n75                maelle   2   3   1           |\n76                  noël   2   3   1           |\n77               justine   2   3   1           |\n78             vaisselle   5   6   1           |\n79              facebook   3   4   1           |\n80                    2a   6   6   0           |\n81               apoulpo   3   3   0           |\n82                 covid  11  11   0           |\n83                   qcm   4   4   0           |\n84                airbnb   6   6   0           |\n85                  wiwi   5   5   0           |\n86            poulpywood  10   9  -1           |\n87                 gradi   6   5  -1           |\n88                 rouge   4   3  -1           |\n89               olivier   6   4  -2          -|\n90                canada   4   2  -2          -|\n91                orange   5   3  -2          -|\n92               kermess   4   1  -3         --|\n93                  gala   7   4  -3         --|\n94                    pc   5   1  -4         --|\n"
     ]
    }
   ],
   "source": [
    "plot_result(df_senti,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 Entités  +   -   %\n------------------------------------------------------------------------------------------------------------------------\n1                     ia   1  11  92                             |+++++++++++++++++++++++++++++++++++\n2                 tiktok   1   8  89                             |++++++++++++++++++++++++++++++++\n3                   hugo   1   7  88                             |+++++++++++++++++++++++++++++++\n4                turn up   1   7  88                             |+++++++++++++++++++++++++++++++\n5                 albane   4  29  88                             |+++++++++++++++++++++++++++++++\n6                 lydia    2  14  88                             |+++++++++++++++++++++++++++++++\n7                 ricard   1   7  88                             |+++++++++++++++++++++++++++++++\n8                   rhum   1   7  88                             |+++++++++++++++++++++++++++++++\n9                    pii   2  12  86                             |++++++++++++++++++++++++++++++\n10                   léa   2  12  86                             |++++++++++++++++++++++++++++++\n11                 vodka   2  11  85                             |+++++++++++++++++++++++++++++\n12              election   4  22  85                             |+++++++++++++++++++++++++++++\n13                    ru   4  19  83                             |++++++++++++++++++++++++++++\n14              campagne   4  20  83                             |++++++++++++++++++++++++++++\n15               discord   2  10  83                             |++++++++++++++++++++++++++++\n16                projet   6  26  81                             |++++++++++++++++++++++++++\n17                 élise   7  28  80                             |+++++++++++++++++++++++++\n18                 simon   8  31  79                             |+++++++++++++++++++++++++\n19                    3a   6  22  79                             |+++++++++++++++++++++++++\n20                  paul   8  29  78                             |++++++++++++++++++++++++\n21                 julie  39 138  78                             |++++++++++++++++++++++++\n22                google   8  28  78                             |++++++++++++++++++++++++\n23              juliette  13  43  77                             |+++++++++++++++++++++++\n24               calabar   2   6  75                             |++++++++++++++++++++++\n25                  info   5  15  75                             |++++++++++++++++++++++\n26                soirée  19  56  75                             |++++++++++++++++++++++\n27               matthéo  12  32  73                             |++++++++++++++++++++\n28               shotgun   4  11  73                             |++++++++++++++++++++\n29                  theo   7  19  73                             |++++++++++++++++++++\n30                   wec  17  45  73                             |++++++++++++++++++++\n31               poulpas   3   8  73                             |++++++++++++++++++++\n32                romain  11  28  72                             |+++++++++++++++++++\n33                marine   5  13  72                             |+++++++++++++++++++\n34               antoine  15  36  71                             |+++++++++++++++++++\n35                 fanny  10  25  71                             |+++++++++++++++++++\n36                wei&go   2   5  71                             |+++++++++++++++++++\n37             instagram   3   7  70                             |++++++++++++++++++\n38                 respo   9  20  69                             |+++++++++++++++++\n39                margot  14  31  69                             |+++++++++++++++++\n40                julien  22  47  68                             |++++++++++++++++\n41                 apéro   4   8  67                             |+++++++++++++++\n42                   wei  10  20  67                             |+++++++++++++++\n43             octoflix    8  16  67                             |+++++++++++++++\n44                 bière  18  37  67                             |+++++++++++++++\n45              bordeaux  11  20  65                             |++++++++++++++\n46          compte rendu   8  15  65                             |++++++++++++++\n47                  zoom  25  44  64                             |+++++++++++++\n48                   bds  12  21  64                             |+++++++++++++\n49                  théa   4   7  64                             |+++++++++++++\n50              corentin   9  16  64                             |+++++++++++++\n51                  tess  17  30  64                             |+++++++++++++\n52                  pull  24  42  64                             |+++++++++++++\n53                    tp   7  12  63                             |++++++++++++\n54               sabaidi  11  18  62                             |++++++++++++\n55               mélissa   3   5  62                             |++++++++++++\n56                  vert  14  22  61                             |+++++++++++\n57                  evan   7  10  59                             |+++++++++\n58                nico l  18  26  59                             |+++++++++\n59                   bde  28  40  59                             |+++++++++\n60                    cm  41  60  59                             |+++++++++\n61                 maths   8  11  58                             |+++++++++\n62              vacances   8  11  58                             |+++++++++\n63              facebook   3   4  57                             |++++++++\n64                  meuf  12  15  56                             |+++++++\n65             vaisselle   5   6  55                             |++++++\n66                  ensc  50  61  55                             |++++++\n67                   bda   9  11  55                             |++++++\n68                 foyer  16  18  53                             |+++++\n69                    1a  17  19  53                             |+++++\n70                  gars  34  37  52                             |++++\n71                 tom d  19  21  52                             |++++\n72                  wiwi   5   5  50                             |+++\n73                airbnb   6   6  50                             |+++\n74                   qcm   4   4  50                             |+++\n75                    2a   6   6  50                             |+++\n76                 covid  11  11  50                             |+++\n77            poulpywood  10   9  47                             |\n78                 gradi   6   5  45                            -|\n79                 rouge   4   3  43                          ---|\n80               olivier   6   4  40                        -----|\n81                orange   5   3  38                      -------|\n82                  gala   7   4  36                     --------|\n"
     ]
    }
   ],
   "source": [
    "index = df_senti[df_senti[\"positif\"]+df_senti[\"negatif\"] <= 6].index\n",
    "plot_result(df_senti.drop(index),4)\n",
    "#pourcentage de sentiment positif parmis tous les sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}